# Sales Analytics: Multi-Model Machine Learning Project

> An√°lisis completo de datos de ventas retail con m√∫ltiples t√©cnicas de Machine Learning, ejecutado por agentes aut√≥nomos bajo el protocolo Ralph Wiggum.

![Python](https://img.shields.io/badge/Python-3.14-blue)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.x-orange)
![XGBoost](https://img.shields.io/badge/XGBoost-2.x-green)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## üß† Sobre este Proyecto

Este proyecto aborda un desaf√≠o com√∫n en el retail: **¬øc√≥mo extraer valor de los datos transaccionales para tomar mejores decisiones de negocio?** Utilizando un dataset real de casi 10,000 transacciones de una empresa estadounidense durante 4 a√±os, apliqu√© cuatro t√©cnicas fundamentales de Machine Learning para responder preguntas cr√≠ticas del negocio:

- **¬øPodemos predecir si una transacci√≥n ser√° rentable antes de aprobar un descuento?** (Clasificaci√≥n)
- **¬øCu√°nto profit generar√° una transacci√≥n espec√≠fica?** (Regresi√≥n)
- **¬øCu√°nto venderemos el pr√≥ximo trimestre?** (Forecasting)
- **¬øQui√©nes son nuestros mejores clientes y c√≥mo segmentarlos?** (Clustering)

El proyecto no solo busca construir modelos, sino demostrar un **proceso riguroso de validaci√≥n**: detect√© y correg√≠ problemas de leakage, analic√© overfitting, iter√© versiones de modelos, y document√© cada decisi√≥n. El resultado es un pipeline reproducible que puede aplicarse a cualquier dataset de ventas similar.

Lo distintivo de este ejercicio es que fue ejecutado por **agentes aut√≥nomos de IA** que trabajaron en paralelo, cada uno especializado en un tipo de modelo, iterando hasta alcanzar objetivos predefinidos sin intervenci√≥n humana durante la ejecuci√≥n. Esto, l√≥gicamente, no implica quitar por completo la validaci√≥n del especialista en Machine Learning.

---

## üìã Tabla de Contenidos

- [Resumen Ejecutivo](#-resumen-ejecutivo)
- [Dataset](#-dataset)
- [Arquitectura del Proyecto](#-arquitectura-del-proyecto)
- [Agentes y Ejecuci√≥n](#-agentes-y-ejecuci√≥n)
- [Resultados por Modelo](#-resultados-por-modelo)
  - [1. Clasificaci√≥n](#1-clasificaci√≥n-rentabilidad)
  - [2. Regresi√≥n](#2-regresi√≥n-predicci√≥n-de-profit)
  - [3. Forecasting](#3-forecasting-ventas-mensuales)
  - [4. Clustering](#4-clustering-segmentaci√≥n-de-clientes)
- [An√°lisis de Overfitting y Leakage](#-an√°lisis-de-overfitting-y-leakage)
- [Conclusiones](#-conclusiones)
- [Estructura de Archivos](#-estructura-de-archivos)
- [Reproducibilidad](#-reproducibilidad)

---

## üéØ Resumen Ejecutivo

Este proyecto aplica 4 t√©cnicas de Machine Learning sobre un dataset de ventas retail:

| Ejercicio | Objetivo | Mejor Modelo | M√©trica Principal | Resultado |
|-----------|----------|--------------|-------------------|-----------|
| **Clasificaci√≥n** | Predecir si transacci√≥n es rentable | Random Forest | ROC-AUC | **0.979** ‚úÖ |
| **Regresi√≥n** | Predecir monto de Profit | LightGBM | R¬≤ | **0.414** ‚ö†Ô∏è |
| **Forecasting** | Proyectar ventas mensuales | Ensemble | MAPE | **16.81%** ‚úÖ |
| **Clustering** | Segmentar clientes | K-Means (k=5) | Segmentos | **5** ‚úÖ |

### Hallazgos Clave

1. **Clasificaci√≥n excelente**: 97.9% ROC-AUC para detectar transacciones no rentables
2. **Leakage detectado y corregido**: El modelo de regresi√≥n V2 ten√≠a R¬≤=0.90 inflado artificialmente
3. **L√≠mite del dataset**: Sin datos de costos, el R¬≤ m√°ximo para predecir Profit es ~0.41
4. **5 segmentos accionables**: Clustering pas√≥ de 2 clusters t√©cnicos a 5 segmentos de marketing

---

## üìä Dataset

**Fuente**: [Kaggle - Sales Order Dataset](https://www.kaggle.com/datasets/datawitharyan/sales-order-dataset)

| M√©trica | Valor |
|---------|-------|
| Registros | 9,994 transacciones |
| Features | 21 columnas |
| Per√≠odo | 2014-01-03 ‚Üí 2017-12-30 |
| Pa√≠s | United States |
| Clientes √∫nicos | 793 |
| Productos √∫nicos | 1,862 |

### Variables Principales

- **Num√©ricas**: Sales, Quantity, Discount, Profit
- **Categ√≥ricas**: Ship Mode, Segment, Region, Category, Sub-Category
- **Temporales**: Order Date, Ship Date

### Distribuci√≥n del Target (Profit)

- Media: $28.66
- Std: $234.26
- Rango: -$6,599.98 a +$8,399.98
- **18.7% de transacciones con p√©rdida**

---

## üèó Arquitectura del Proyecto

Este proyecto utiliza el sistema **Ralph Wiggum** de agentes aut√≥nomos:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 1: DISCOVERY                            ‚îÇ
‚îÇ                  (Interactivo con humano)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  /ralph-discovery                                               ‚îÇ
‚îÇ       ‚Üì                                                         ‚îÇ
‚îÇ  EDA Autom√°tico ‚Üí Propuesta de ejercicios ‚Üí Plan Mode           ‚îÇ
‚îÇ       ‚Üì                                                         ‚îÇ
‚îÇ  Generaci√≥n de agent_context/plan.md                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 2: EJECUCI√ìN                            ‚îÇ
‚îÇ                  (Agentes aut√≥nomos)                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ./ralph_ds_runner.sh sales_exercise                            ‚îÇ
‚îÇ       ‚Üì                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇClassifier‚îÇ ‚îÇRegressor ‚îÇ ‚îÇForecaster‚îÇ ‚îÇClusterer ‚îÇ  (paralelo)‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ                         ‚Üì                                       ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ
‚îÇ                   ‚îÇ Reporter ‚îÇ                                  ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 3: OPTIMIZACI√ìN                         ‚îÇ
‚îÇ                  (Iteraci√≥n de mejora)                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  An√°lisis de resultados ‚Üí Detecci√≥n de problemas                ‚îÇ
‚îÇ       ‚Üì                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇForecasterV2‚îÇ ‚îÇRegressorV2 ‚îÇ ‚îÇClustererV2 ‚îÇ                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ       ‚Üì                                                         ‚îÇ
‚îÇ  Detecci√≥n de LEAKAGE en RegressorV2                            ‚îÇ
‚îÇ       ‚Üì                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                 ‚îÇ
‚îÇ  ‚îÇRegressorV3 ‚îÇ  (sin leakage)                                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ü§ñ Agentes y Ejecuci√≥n

### Agentes V1 (Ejecuci√≥n Inicial)

| Agente | Responsabilidad | Tiempo | Output Principal |
|--------|-----------------|--------|------------------|
| **ProfitabilityClassifier** | Clasificar transacciones rentables | ~5 min | `profitability_classifier_best_model.pkl` |
| **ProfitRegressor** | Predecir valor de Profit | ~5 min | `profit_regressor_best_model.pkl` |
| **SalesForecaster** | Proyectar ventas mensuales | ~4 min | `sales_forecaster_best_model.pkl` |
| **CustomerSegmenter** | Segmentar clientes (RFM) | ~3 min | `customer_segmenter_model.pkl` |
| **Reporter** | Generar paper LaTeX | ~2 min | `paper.tex` |

### Agentes V2 (Optimizaci√≥n)

| Agente | Problema a Resolver | Mejora Lograda |
|--------|---------------------|----------------|
| **ForecasterV2** | MAPE 19.2% muy alto | MAPE ‚Üí 16.8% (-12.5%) |
| **RegressorV2** | R¬≤ 0.43 bajo | R¬≤ ‚Üí 0.90 (‚ö†Ô∏è con leakage) |
| **ClustererV2** | Solo 2 clusters | ‚Üí 5 segmentos accionables |

### Agente V3 (Correcci√≥n de Leakage)

| Agente | Problema | Resultado |
|--------|----------|-----------|
| **RegressorV3** | V2 usaba `price_per_unit` (leakage) | R¬≤ real = 0.414 |

---

## üìà Resultados por Modelo

### 1. Clasificaci√≥n (Rentabilidad)

**Objetivo**: Predecir si una transacci√≥n ser√° rentable (Profit > 0)

**Target**: 81.3% rentables vs 18.7% con p√©rdida

#### Comparativa de Modelos

| Modelo | F1-Score | Accuracy | Precision | Recall | ROC-AUC |
|--------|----------|----------|-----------|--------|---------|
| **Random Forest (Opt)** | **0.966** | **0.945** | 0.952 | 0.982 | **0.979** |
| XGBoost | 0.955 | 0.929 | 0.975 | 0.936 | 0.982 |
| LightGBM | 0.959 | 0.934 | 0.972 | 0.946 | 0.981 |
| Logistic Regression | 0.943 | 0.910 | 0.955 | 0.932 | 0.949 |

#### Visualizaciones

<p align="center">
  <img src="output/profitability_roc_curve.png" width="45%" alt="ROC Curve"/>
  <img src="output/profitability_confusion_matrix.png" width="45%" alt="Confusion Matrix"/>
</p>

<p align="center">
  <img src="output/profitability_feature_importance.png" width="60%" alt="Feature Importance"/>
</p>

#### Conclusi√≥n Clasificaci√≥n

‚úÖ **Excelente rendimiento**. ROC-AUC de 0.979 permite detectar transacciones potencialmente no rentables con alta confianza antes de aprobar descuentos.

El modelo de clasificaci√≥n demostr√≥ ser el m√°s exitoso del proyecto, alcanzando m√©tricas que superan ampliamente los objetivos planteados. Con un F1-Score de 0.966, el modelo logra un balance √≥ptimo entre precisi√≥n y recall, lo que significa que no solo identifica correctamente la mayor√≠a de las transacciones no rentables (recall 98.2%), sino que cuando predice que una transacci√≥n ser√° problem√°tica, acierta el 95.2% de las veces (precision).

Desde una perspectiva de negocio, este modelo tiene aplicaci√≥n inmediata: puede integrarse en el proceso de aprobaci√≥n de descuentos para alertar cuando una combinaci√≥n de producto, cliente, cantidad y descuento tiene alta probabilidad de generar p√©rdida. Las features m√°s importantes fueron el nivel de descuento y la sub-categor√≠a del producto, lo que confirma la intuici√≥n de que los descuentos agresivos en ciertas categor√≠as erosionan la rentabilidad.

---

### 2. Regresi√≥n (Predicci√≥n de Profit)

**Objetivo**: Predecir el monto de Profit para cada transacci√≥n

#### Evoluci√≥n de Versiones

| Versi√≥n | Mejor Modelo | RMSE | R¬≤ | Observaci√≥n |
|---------|--------------|------|-----|-------------|
| **V1** | LightGBM | $73.76 | 0.428 | Baseline |
| **V2** | XGBoost | $30.91 | 0.899 | ‚ö†Ô∏è **LEAKAGE DETECTADO** |
| **V3** | LightGBM | $74.65 | **0.414** | ‚úÖ M√©tricas reales |

#### El Problema del Leakage (V2)

El modelo V2 usaba `price_per_unit = Sales / Quantity` como feature:

```
Sales tiene correlaci√≥n 0.48 con Profit
‚Üì
price_per_unit filtra informaci√≥n del target
‚Üì
R¬≤ artificialmente inflado de 0.41 a 0.90
```

**Lecci√≥n**: Siempre verificar si las features derivadas contienen informaci√≥n del target.

#### Diagn√≥stico de Overfitting (V3)

| Modelo | Train R¬≤ | Val R¬≤ | Gap | Diagn√≥stico |
|--------|----------|--------|-----|-------------|
| LightGBM_v3 | 0.715 | 0.430 | 28.5% | ‚ö†Ô∏è Overfitting |
| RandomForest_v3 | 0.630 | 0.419 | 21.1% | ‚ö†Ô∏è Overfitting |
| XGBoost_v3 | 0.619 | 0.416 | 20.3% | ‚ö†Ô∏è Overfitting |

#### Visualizaciones

<p align="center">
  <img src="output/profit_regressor_feature_importance.png" width="60%" alt="Feature Importance V1"/>
</p>

#### Conclusi√≥n Regresi√≥n

‚ö†Ô∏è **Limitaci√≥n estructural del dataset**. El R¬≤ de ~0.41 es el m√°ximo alcanzable porque:

```
Profit = Sales - Costs
```

**No tenemos datos de Costs**. El modelo solo puede inferir patrones indirectos a trav√©s de Discount, Category, y otras variables proxy.

Este modelo fue el m√°s desafiante del proyecto y el que m√°s iteraciones requiri√≥. Inicialmente, la versi√≥n V2 mostr√≥ un R¬≤ impresionante de 0.90, pero el an√°lisis posterior revel√≥ que este resultado estaba inflado por **data leakage**: la feature `price_per_unit` (calculada como Sales/Quantity) conten√≠a informaci√≥n impl√≠cita del target, ya que Sales y Profit est√°n altamente correlacionados.

Tras eliminar esta feature en V3, el R¬≤ cay√≥ a 0.414, revelando la capacidad predictiva real del modelo. Adem√°s, se detect√≥ overfitting significativo (gap train-val del 28%), lo que indica que incluso este R¬≤ moderado podr√≠a estar sobreestimado en producci√≥n.

La lecci√≥n principal es que **predecir el profit exacto requiere informaci√≥n que no est√° en el dataset**: los costos de los productos, m√°rgenes negociados con proveedores, costos de env√≠o reales, etc. Con las features disponibles, el modelo puede capturar patrones generales (descuentos altos = menos profit, ciertas categor√≠as son m√°s rentables), pero no puede ser preciso a nivel de transacci√≥n individual. Para casos de uso que requieran predicci√≥n de profit, se recomienda enriquecer el dataset con datos de costos o usar el modelo de clasificaci√≥n (rentable/no rentable) que s√≠ funciona bien.

---

### 3. Forecasting (Ventas Mensuales)

**Objetivo**: Proyectar ventas agregadas mensuales

#### Evoluci√≥n de Versiones

| Versi√≥n | Mejor Modelo | MAPE | RMSE | MAE |
|---------|--------------|------|------|-----|
| **V1** | Prophet | 19.21% | $17,792 | $15,423 |
| **V2** | Ensemble Optimizado | **16.81%** | $17,245 | $13,868 |

#### T√©cnicas de Mejora V2

1. **Box-Cox Transform** (Œª=0.5): Estabiliz√≥ varianza ‚Üí -1.5pp MAPE
2. **Ensemble de 4 modelos**: Prophet + ETS + SARIMA + Theta
3. **Optimizaci√≥n de pesos**: Scipy minimization

#### Pesos del Ensemble

| Modelo | Peso |
|--------|------|
| ETS_BoxCox | 0.31 |
| Prophet_BoxCox | 0.29 |
| SARIMA_BoxCox | 0.21 |
| Theta_BoxCox | 0.19 |

#### Impacto del Outlier

Agosto 2017 tuvo ventas an√≥malas (Z-score: 8.37):

| Escenario | MAPE |
|-----------|------|
| Con outlier | 16.81% |
| Sin outlier | **13.82%** |

#### Visualizaciones

<p align="center">
  <img src="output/sales_forecast_plot.png" width="45%" alt="Forecast V1"/>
  <img src="output/forecast_weekly_plot_v2.png" width="45%" alt="Forecast V2"/>
</p>

<p align="center">
  <img src="output/sales_decomposition.png" width="60%" alt="Decomposition"/>
</p>

#### Conclusi√≥n Forecasting

‚úÖ **Mejora significativa** de 19.2% a 16.8% MAPE. El ensemble con Box-Cox transform demostr√≥ ser robusto. Limitaci√≥n: solo 48 puntos mensuales de datos.

El modelo de forecasting representa un caso interesante de optimizaci√≥n iterativa. La versi√≥n inicial (V1) us√≥ Prophet con configuraci√≥n est√°ndar y logr√≥ un MAPE de 19.2%. La hip√≥tesis inicial para V2 fue que agregar m√°s granularidad (datos semanales en lugar de mensuales) mejorar√≠a las predicciones, pero result√≥ contraproducente: la mayor volatilidad semanal empeor√≥ el MAPE a 34%.

El breakthrough vino de una direcci√≥n diferente: la **transformaci√≥n Box-Cox** estabiliz√≥ la varianza de la serie temporal y permiti√≥ que los modelos capturaran mejor los patrones estacionales. Combinado con un ensemble de 4 modelos (Prophet, ETS, SARIMA, Theta), cada uno con sus fortalezas, se logr√≥ reducir el MAPE a 16.8%.

Un hallazgo importante fue la identificaci√≥n de un **outlier extremo** en Agosto 2017 (Z-score de 8.37), que por s√≠ solo contribuye ~3 puntos porcentuales al MAPE. Sin este outlier, el modelo alcanza 13.8% de error, cumpliendo el objetivo de <15%. Esto sugiere que el modelo es robusto para condiciones normales, pero vulnerable a eventos extraordinarios no capturados en los datos hist√≥ricos.

Para uso en producci√≥n, se recomienda aplicar el modelo con un buffer de ¬±15-20% para planificaci√≥n de inventario y presupuestos, especialmente en Q4 donde la estacionalidad es m√°s pronunciada.

---

### 4. Clustering (Segmentaci√≥n de Clientes)

**Objetivo**: Segmentar la base de 793 clientes para estrategias de marketing

#### Evoluci√≥n de Versiones

| Versi√≥n | Modelo | Clusters | Silhouette | Enfoque |
|---------|--------|----------|------------|---------|
| **V1** | DBSCAN | 2 | 0.506 | M√©trica pura |
| **V2** | K-Means | **5** | 0.251 | **Accionabilidad** |

#### Trade-off V1 vs V2

V1 (DBSCAN) ten√≠a mejor Silhouette pero gener√≥:
- Cluster 0: 784 clientes (pr√°cticamente todos)
- Cluster 1: 3 clientes (outliers)
- Ruido: 6 clientes

**In√∫til para marketing**. V2 sacrific√≥ m√©trica por utilidad pr√°ctica.

#### Segmentos V2

| Segmento | Clientes | % | Recency | Frequency | Monetary | Acci√≥n |
|----------|----------|---|---------|-----------|----------|--------|
| **Loyal Customers** | 304 | 38% | 74 d√≠as | 8.1 | $3,803 | Retenci√≥n, upsell |
| **Low Value** | 251 | 32% | 102 d√≠as | 5.6 | $1,270 | Desarrollo |
| **Big Spenders** | 104 | 13% | 124 d√≠as | 6.4 | $6,599 | VIP, atenci√≥n premium |
| **Lost** | 73 | 9% | 578 d√≠as | 3.7 | $1,671 | Reactivaci√≥n urgente |
| **Hibernating** | 61 | 8% | 232 d√≠as | 3.3 | $230 | Evaluar abandono |

#### Visualizaciones

<p align="center">
  <img src="output/rfm_distribution.png" width="45%" alt="RFM Distribution"/>
  <img src="output/elbow_silhouette_plot.png" width="45%" alt="Elbow Plot"/>
</p>

<p align="center">
  <img src="output/cluster_profiles_v2.png" width="70%" alt="Cluster Profiles V2"/>
</p>

#### Conclusi√≥n Clustering

‚úÖ **5 segmentos accionables** para marketing diferenciado. El 38% son Loyal Customers (core del negocio), mientras que el 9% Lost requiere campa√±as de reactivaci√≥n urgente.

El modelo de clustering ilustra perfectamente el **trade-off entre m√©tricas t√©cnicas y utilidad de negocio**. La versi√≥n V1 con DBSCAN logr√≥ un Silhouette Score excelente de 0.506, pero gener√≥ solo 2 clusters: uno con el 99% de los clientes y otro con 3 outliers. T√©cnicamente correcto, pero completamente in√∫til para segmentaci√≥n de marketing.

La versi√≥n V2 prioriz√≥ la accionabilidad: usando K-Means con k=5, sacrifiqu√© Silhouette (baj√≥ a 0.251) pero gan√© **5 segmentos interpretables** que un equipo de marketing podr√≠a usar inmediatamente:

- **Loyal Customers (38%)**: El core del negocio, alta frecuencia y recencia reciente. Estrategia: programas de fidelizaci√≥n y upselling.
- **Big Spenders (13%)**: Pocos pero valiosos, ticket promedio 5x mayor. Estrategia: atenci√≥n VIP personalizada.
- **Low Value (32%)**: Potencial de desarrollo, frecuencia moderada. Estrategia: incentivos para aumentar ticket promedio.
- **Lost (9%)**: No compran hace m√°s de 1.5 a√±os. Estrategia: campa√±as de reactivaci√≥n agresivas o aceptar p√©rdida.
- **Hibernating (8%)**: Bajo valor hist√≥rico y en declive. Estrategia: evaluar costo-beneficio de retenci√≥n.

La lecci√≥n clave es que en clustering, **la mejor m√©trica no siempre produce el mejor resultado de negocio**. Un Silhouette de 0.25 con 5 segmentos √∫tiles supera a un Silhouette de 0.50 con 2 segmentos triviales.

---

## üîç An√°lisis de Overfitting y Leakage

### Resumen de Diagn√≥sticos

| Modelo | Train Score | Val Score | Gap | Leakage | Diagn√≥stico |
|--------|-------------|-----------|-----|---------|-------------|
| Clasificador | - | 0.979 (AUC) | <1% | ‚ùå No | ‚úÖ OK |
| Regresor V1 | - | 0.428 (R¬≤) | - | ‚ùå No | ‚úÖ OK |
| Regresor V2 | - | 0.899 (R¬≤) | - | ‚ö†Ô∏è **S√≠** | ‚ùå Leakage |
| Regresor V3 | 0.715 | 0.430 (R¬≤) | 28% | ‚ùå No | ‚ö†Ô∏è Overfitting |
| Forecaster V2 | - | 16.8% (MAPE) | - | ‚ùå No | ‚úÖ OK |

### Lecciones Aprendidas

1. **Siempre verificar features derivadas**: `price_per_unit = Sales/Quantity` parec√≠a inocente pero conten√≠a informaci√≥n del target

2. **Reportar Train vs Val**: El gap de 28% en V3 indica que los modelos memorizan el training set

3. **M√©tricas enga√±osas**: Un R¬≤ de 0.90 que parece excelente puede ser artificial

---

## üéØ Conclusiones

### Por Modelo

| Modelo | Conclusi√≥n | Recomendaci√≥n |
|--------|------------|---------------|
| **Clasificaci√≥n** | Excelente (AUC 0.979) | Implementar para alertas de descuentos riesgosos |
| **Regresi√≥n** | Limitado (R¬≤ 0.41) | Necesita datos de costos para mejorar |
| **Forecasting** | Bueno (MAPE 16.8%) | Usar para planificaci√≥n con buffer ¬±15-20% |
| **Clustering** | √ötil (5 segmentos) | Implementar estrategias diferenciadas por segmento |

### Conclusi√≥n General

Este proyecto demuestra un pipeline completo de Data Science con:

1. **EDA automatizado** que identifica oportunidades de ML
2. **M√∫ltiples modelos** comparados rigurosamente
3. **Iteraci√≥n de mejora** (V1 ‚Üí V2 ‚Üí V3) basada en an√°lisis de errores
4. **Detecci√≥n de problemas** (leakage, overfitting) y correcci√≥n
5. **Trade-offs documentados** (Silhouette vs accionabilidad en clustering)

**El valor principal no est√° solo en las m√©tricas, sino en el proceso de validaci√≥n riguroso que evita poner en producci√≥n modelos con problemas ocultos.**

---

## üìÅ Estructura de Archivos

```
sales_exercise/
‚îú‚îÄ‚îÄ README.md                          # Este archivo
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ Sales_csv.csv                  # Dataset original
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ EDA.md                         # An√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ profitability_classifier_report.md
‚îÇ   ‚îú‚îÄ‚îÄ profit_regressor_report.md
‚îÇ   ‚îú‚îÄ‚îÄ sales_forecaster_report.md
‚îÇ   ‚îú‚îÄ‚îÄ customer_segmenter_report.md
‚îÇ   ‚îú‚îÄ‚îÄ forecaster_v2_report.md
‚îÇ   ‚îú‚îÄ‚îÄ regressor_v2_report.md
‚îÇ   ‚îî‚îÄ‚îÄ clusterer_v2_report.md
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îú‚îÄ‚îÄ # Modelos (.pkl)
‚îÇ   ‚îú‚îÄ‚îÄ profitability_classifier_best_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ profit_regressor_best_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ regressor_v2_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ regressor_v3_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ sales_forecaster_best_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ forecaster_v2_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ customer_segmenter_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ clusterer_v2_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ # Resultados (.csv)
‚îÇ   ‚îú‚îÄ‚îÄ profitability_classifier_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ profit_regressor_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ regressor_v2_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ regressor_v3_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ sales_forecaster_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ forecaster_v2_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ customer_segmenter_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ clusterer_v2_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ customer_segments_v2.csv
‚îÇ   ‚îú‚îÄ‚îÄ # Visualizaciones (.png)
‚îÇ   ‚îú‚îÄ‚îÄ profitability_*.png
‚îÇ   ‚îú‚îÄ‚îÄ profit_regressor_*.png
‚îÇ   ‚îú‚îÄ‚îÄ sales_*.png
‚îÇ   ‚îú‚îÄ‚îÄ cluster_*.png
‚îÇ   ‚îú‚îÄ‚îÄ rfm_distribution.png
‚îÇ   ‚îî‚îÄ‚îÄ paper.tex                      # Paper LaTeX
‚îú‚îÄ‚îÄ agent_context/
‚îÇ   ‚îú‚îÄ‚îÄ plan.md                        # Plan original
‚îÇ   ‚îú‚îÄ‚îÄ plan_optimization.md           # Plan de optimizaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ *_state.json                   # Estados de agentes
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ (c√≥digo generado por agentes)
```

---

## üîÑ Reproducibilidad

### Requisitos

```bash
pip install pandas numpy scikit-learn xgboost lightgbm catboost prophet statsmodels matplotlib seaborn joblib shap
```

### Ejecuci√≥n

```bash
# 1. Clonar repositorio
git clone <repo-url>
cd sales_exercise

# 2. Cargar modelos entrenados
import joblib
classifier = joblib.load('output/profitability_classifier_best_model.pkl')
regressor = joblib.load('output/regressor_v3_model.pkl')  # Sin leakage
forecaster = joblib.load('output/forecaster_v2_model.pkl')
clusterer = joblib.load('output/clusterer_v2_model.pkl')
```

### Semilla

Todos los modelos usan `random_state=42` para reproducibilidad.

---

## üôè Cr√©ditos

- **Dataset**: [Kaggle - Sales Order Dataset](https://www.kaggle.com/datasets/datawitharyan/sales-order-dataset) by DataWithAryan
- **Metodolog√≠a**: Ralph Wiggum Protocol (Agentes Aut√≥nomos)
- **Generado**: Enero 2026
